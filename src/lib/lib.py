import pandas as pd
from datetime import timedelta
import plotly.graph_objects as go
import streamlit as st
from plotly.subplots import make_subplots
import numpy as np
from ds_dbconn import ds_databricks


class Summary_AnalysisTools:

    # ì´ í•¨ìˆ˜ëŠ” float íƒ€ì…ì˜ ê°’ì„ ë°±ë¶„ìœ¨ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    def format_inf(self,value):
        if value == float("inf") or value == float("-inf") or pd.isnull(value):
            return np.nan
        return value

    def format_percentage(self,value):
        if value == float("inf") or value == float("-inf") or pd.isnull(value):
            return "-"
        return f"{value:,.1f}%"

    # 'Signal' ì»¬ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    def signal_indicator(self,change):
        if change < 0:
            return 'ğŸŸ¢'  # ì–‘ìˆ˜ì¸ ê²½ìš° ë…¹ìƒ‰ ì›
        elif change > 0:
            return 'ğŸ”´'  # ìŒìˆ˜ì¸ ê²½ìš° ë¹¨ê°„ìƒ‰ ì›
        else:
            return 'ğŸŸ¡'  # 0ì¸ ê²½ìš° ë…¸ë€ìƒ‰ ì›

    def noun_extractor(self,text):
        results = []
        try:
            result = kiwi.analyze(text)
            for token, pos, _, _ in result[0][0]:
                if len(token) != 1 and pos.startswith('N'):
                    results.append(token)
        except Exception:
            # ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ì•„ë¬´ ì¡°ì¹˜ë¥¼ ì·¨í•˜ì§€ ì•Šê³  ë„˜ì–´ê°‘ë‹ˆë‹¤.
            pass
        return results
    
class Trend_AnalysisTools:
  
            
    def select_fault_type(self, df_classify ,start_date, end_date ,selected_plant ,key_suffix, col6_1, col6_2, col6_3):
        df_classify = df_classify[df_classify['wname1'] == selected_plant]
        df_classify['bsymd'] = pd.to_datetime(df_classify['bsymd'])
    
        start_date = pd.to_datetime(start_date).strftime('%Y%m%d')
        end_date = pd.to_datetime(end_date).strftime('%Y%m%d')
        df_classify= df_classify[(df_classify['bsymd'] >= start_date) & (df_classify['bsymd'] <= end_date)].reset_index()

        lcls_nm =df_classify.groupby(['lcls_nm']).sum().sort_values(by='voc_id_count' , ascending = False).index.tolist()
        lcls_nm.insert(0, 'All')  # ëª©ë¡ ì‹œì‘ì— 'All' ì˜µì…˜ ì¶”ê°€

        with col6_1:
            self.selected_lcls = st.selectbox('ë¶ˆëŸ‰ìœ í˜• ì„ íƒ(ëŒ€ë¶„ë¥˜)', lcls_nm, key=f'detail_key_lcls_{key_suffix}')
            selected_lcls  = self.selected_lcls
            with col6_2:
                if selected_lcls == 'All':
                    self.selected_mcls = st.selectbox('ë¶ˆëŸ‰ìœ í˜• ì„ íƒ(ì¤‘ë¶„ë¥˜)', ['All'], key=f'detail_key_lcls_idx_{key_suffix}')
                    selected_mcls  = self.selected_mcls
                
                elif selected_lcls != 'All':
                    df_classify = df_classify[df_classify['lcls_nm'] == selected_lcls]
                    mcls_nm =df_classify.groupby(['mcls_nm']).sum().sort_values(by='voc_id_count' , ascending = False).index.tolist()
                    #mcls_nm = df_classify['mcls_nm'].unique().tolist()
                    
                    mcls_nm.insert(0, 'All')
                    self.selected_mcls = st.selectbox('ë¶ˆëŸ‰ìœ í˜• ì„ íƒ(ì¤‘ë¶„ë¥˜)', mcls_nm, key=f'detail_key_mcls_{key_suffix}')
                    selected_mcls  = self.selected_mcls

                with col6_3:
                        if selected_mcls == 'All':
                            self.selected_scls = st.selectbox('ë¶ˆëŸ‰ìœ í˜• ì„ íƒ(ì†Œë¶„ë¥˜)', ['All'], key=f'detail_key_mcls_idx_{key_suffix}')
                            selected_scls = self.selected_scls
                        elif selected_mcls != 'All':
                            df_classify = df_classify[df_classify['mcls_nm'] == selected_mcls]
                            scls_nm =df_classify.groupby(['scls_nm']).sum().sort_values(by='voc_id_count' , ascending = False).index.tolist()
                            #scls_nm = df_classify['scls_nm'].unique().tolist()
                            scls_nm.insert(0, 'All')
                            self.selected_scls = st.selectbox('ë¶ˆëŸ‰ìœ í˜• ì„ íƒ(ì†Œë¶„ë¥˜)', scls_nm, key=f'detail_key_scls_{key_suffix}')
                            selected_scls = self.selected_scls
                            
                            if selected_scls != 'All':
                                df_classify = df_classify[df_classify['scls_nm'] == selected_scls]
        return df_classify


    def prepare_anomaly_data(self,df, start_date_key ,end_date_key, count_column, date_column , selected_plant):
        # í•œ í•´ ì „ ë‚ ì§œ ê³„ì‚°
        one_year_ago = pd.to_datetime(end_date_key) - timedelta(days=365)
        df_grouped = df.groupby(['bsymd' , 'wname1'])['voc_id_count'].sum().reset_index()
        df_grouped.set_index('bsymd', inplace=True)

        # ë‚ ì§œ ì»¬ëŸ¼ì„ ë‚ ì§œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        if not df_grouped.empty:
            bsymd_as_datetime = pd.to_datetime(df_grouped.index.get_level_values('bsymd'))

            # ìƒˆë¡œìš´ datetime ì¸ë±ìŠ¤ë¡œ ì„¤ì •
            df_grouped.index = bsymd_as_datetime
            df_grouped = df_grouped.resample('D').asfreq()
        

        #st.session_state[start_date]ë¶€í„° ì‹œì‘í•˜ëŠ” ë‚ ì§œ ë²”ìœ„ ìƒì„±
        start_date = pd.to_datetime(start_date_key)
        end_date = pd.to_datetime(end_date_key)  # df_groupedì˜ ìµœëŒ€ ë‚ ì§œ

        date_range = pd.date_range(start=start_date, end=end_date, freq='D')

        # ë‚ ì§œ ë²”ìœ„ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆ DataFrame ìƒì„±
        df_date_range = pd.DataFrame(date_range, columns=[date_column])

        # ìƒˆ DataFrameê³¼ ê¸°ì¡´ df_grouped ë³‘í•©
        df_grouped = pd.merge(df_date_range, df_grouped, on=date_column, how='left')

        

        # wname1 ì—´ì˜ ê²°ì¸¡ì¹˜ë¥¼ ì²« ë²ˆì§¸ ìœ íš¨í•œ ê°’ìœ¼ë¡œ ì±„ì›€
   
        first_valid_wname1 = selected_plant
        df_grouped['wname1'].fillna(first_valid_wname1, inplace=True)
        
        # voc_id ì—´ì˜ ê²°ì¸¡ì¹˜ë¥¼ 0ìœ¼ë¡œ ì±„ì›€
        df_grouped['voc_id_count'].fillna(0, inplace=True)
    
        # ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
        df_filtered = df_grouped[df_grouped[date_column] >= one_year_ago]

        # í‰ê· ê³¼ í‘œì¤€ í¸ì°¨ ê³„ì‚°
        mean = df_filtered[count_column].mean()
        std = df_filtered[count_column].std()

        # ì´ìƒì¹˜ ê³„ì‚°
        df_filtered = df_grouped[df_grouped[date_column] >= start_date]
        df_filtered['upper_bound'] = mean + 3*std
        df_filtered['anomaly'] = df_filtered[count_column] > df_filtered['upper_bound']
        return df_filtered, mean
    


    


    def plot_anomalies(self, df, mean, date_column, count_column, line_color='blue'):
        fig = go.Figure()

        # ì›ë³¸ ë°ì´í„° í”Œë¡¯
        fig.add_trace(go.Scatter(
            x=df[date_column], 
            y=df[count_column],
            mode='lines',
            name='Count',
            line=dict(color=line_color),
            opacity=0.25,
            hovertemplate=f'{date_column}: %{{x}}<br>{count_column}: %{{y}}<extra></extra>'
        ))

        # í‰ê· ì„  í”Œë¡¯
        fig.add_trace(go.Scatter(
            x=df[date_column], 
            y=[mean]*len(df),
            mode='lines',
            name='Average',
            line=dict(color='green', dash='dash'),
            hoverinfo='skip'
        ))

        # ì´ìƒì¹˜ í‘œì‹œ
        anomalies = df[df['anomaly']]
        fig.add_trace(go.Scatter(
            x=anomalies[date_column], 
            y=anomalies[count_column],
            mode='markers',
            name = 'mean(s) + 3sigma(Ïƒ)',
            marker=dict(color='red', size=5),
            hovertemplate=f'{date_column}: %{{x}}<br>{count_column}: %{{y}}<extra></extra>'
        ))

        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig.update_layout(
            xaxis_title='Date',
            yaxis_title='Count',
            showlegend=True
        )
        fig.update_xaxes(range=[df[date_column].min(), df[date_column].max()])

        return fig
    

    def create_combined_anomaly_chart(self, df1, df2, start_date1, end_date1, start_date2, end_date2):
        fig = make_subplots(specs=[[{"secondary_y": False}]])

        # ì²« ë²ˆì§¸ ë°ì´í„° ì„¸íŠ¸ ì²˜ë¦¬
        anomalies1 = df1[df1['anomaly']]
        fig.add_trace(
            go.Scatter(
                x=df1.index,
                y=df1['voc_id_count'],
                mode='lines',
                name=f'"{start_date1}" ~ "{end_date1}" ê¸°ê°„',
                line=dict(color='blue'),
                opacity = 0.25,
                text = df1['bsymd'].dt.strftime('%Y/%m/%d'),
                hovertemplate= f'bsymd: %{{text}}<br>voc_id Count: %{{y}}<extra></extra>'
            ),
            secondary_y=False
        )
        fig.add_trace(
            go.Scatter(
                x=anomalies1.index,
                y=anomalies1['voc_id_count'],
                mode='markers',
                name='Period 1 mean(s) + 3sigma(Ïƒ)',
                marker=dict(color='#FF8C00', size=5),
                text=anomalies1['bsymd'].dt.strftime('%Y/%m/%d'),
                hovertemplate= f'bsymd: %{{text}}<br>voc_id Count: %{{y}}<extra></extra>'
            ),
            secondary_y=False
        )

        # ë‘ ë²ˆì§¸ ë°ì´í„° ì„¸íŠ¸ ì²˜ë¦¬
        anomalies2 = df2[df2['anomaly']]
        fig.add_trace(
            go.Scatter(
                x=df2.index,
                y=df2['voc_id_count'],
                mode='lines',
                name=f'"{start_date2}" ~ "{end_date2}" ê¸°ê°„',
                line=dict(color='red'),
                opacity = 0.25,
                text=df2['bsymd'].dt.strftime('%Y/%m/%d'),
                hovertemplate= f'bsymd: %{{text}}<br>voc_id Count: %{{y}}<extra></extra>'
            ),
            secondary_y=False
        )
        fig.add_trace(
            go.Scatter(
                x=anomalies2.index,
                y=anomalies2['voc_id_count'],
                mode='markers',
                name='Period 2 mean(s) + 3sigma(Ïƒ)',
                marker=dict(color='red', size=5),
                text=anomalies2['bsymd'].dt.strftime('%Y/%m/%d'),
                hovertemplate= f'bsymd: %{{text}}<br>voc_id Count: %{{y}}<extra></extra>'
            ),
            secondary_y=False
        )

        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig.update_layout(
            title="ê²°í•©ëœ ì¼ë³„ VOC ì¶”ì„¸ ë¶„ì„",
            xaxis_title='Date',
            yaxis_title='VOC Count',
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=-0.5,
                xanchor='center',
                x=0.5
            )
        )
        fig.update_xaxes(range=[df1.index.min(), df1.index.max()])

        return fig
    
    def create_graphs_by_classification(self,filter_name, df_classify, fig_bar, fig_pie, color_palette, create_bar=True, create_pie=True):
        total_counts = df_classify.groupby(filter_name)['voc_id_count'].sum()
        unique_keys = total_counts.index.sort_values(ascending=False).tolist()
        colors = color_palette[:len(unique_keys)]
        color_dict = dict(zip(unique_keys, colors))
        
        # ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±
        if create_bar:
            sorted_keywords = total_counts.sort_values(ascending=False).index.tolist()

            for keyword in sorted_keywords:
                keyword_df = df_classify[df_classify[filter_name] == keyword]
                keyword_counts = keyword_df.groupby(keyword_df.index)['voc_id_count'].sum()
                
                fig_bar.add_trace(go.Bar(
                    x=keyword_counts.index,
                    y=keyword_counts,
                    name=f'{keyword} VOC Count',
                    marker=dict(color=color_dict[keyword]),
                    hoverinfo='none',
                    hovertemplate=f'{keyword} VOC Count<br>' +'bsymd: %{x|%Y/%m/%d}<br>voc_id: %{y}<extra></extra>'

                ))
            fig_bar.update_layout(xaxis=dict(tickformat='%y/%m/%d'), height=500)

        # íŒŒì´ ì°¨íŠ¸ ìƒì„±
        if create_pie:
            fig_pie.add_trace(go.Pie(
                labels=unique_keys,
                values=[total_counts[keyword] for keyword in unique_keys],
                hole=.3,
                marker=dict(colors=[color_dict[keyword] for keyword in unique_keys]),
                sort=True
            ))

        return fig_bar, fig_pie






class Anomaly_AnalysisTools:
    
    def load_data(self,table):
        # ë°ì´í„° ë¡œë“œ
        df = ds_databricks.select_all("*", "b10g000565.cis_ano." + f"{table}")
        return df